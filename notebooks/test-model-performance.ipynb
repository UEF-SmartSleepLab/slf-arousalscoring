{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPU visibility\n",
    "from slf_simultscoring.train import set_gpu_visibility\n",
    "set_gpu_visibility(\"1\", tf_cpu_only=False)\n",
    "\n",
    "import sleeplab_format as slf\n",
    "import sleeplab_tf_dataset as sds #Needs to be imported after setting visible devices\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, cohen_kappa_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "seed = 42 #make sure you have the same seed as in training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to configuration file\n",
    "config_path = '/home/hennpi/Documents/SLF/slf-arousalscoring/config_files/tensorflow_MESA_arousals.yml'\n",
    "\n",
    "# path to model\n",
    "model_path = '/wrk/hennpi/models/slf-simultscoring/MESA_arousals/best_model_20250325_142347.keras'\n",
    "\n",
    "# retrieve correct information from config file\n",
    "ds_name = 'MESA'\n",
    "output_name = 'arousals'\n",
    "\n",
    "# if you don't want to save: savepath = None\n",
    "savepath = None #Path('/home/hennpi/Documents',f\"{ds_name}_{output_name}_{model_path.split('/')[-1].split('.keras')[0]}.mat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get config file for model and dataset\n",
    "with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model from model_path\n",
    "model = tf.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the model\n",
    "\n",
    "tf.keras.utils.plot_model(\n",
    "    model,\n",
    "    show_shapes=False,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=False,\n",
    "    rankdir='TB',\n",
    "    expand_nested=False,\n",
    "    dpi=200,\n",
    "    show_layer_activations=False,\n",
    "    show_trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split subject IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dir = Path(config['datasets'][ds_name]['ds_dir'])\n",
    "series_name = config['datasets'][ds_name]['series_name']\n",
    "\n",
    "# Read the slf Dataset\n",
    "logger.info(f'Reading SLF dataset from {ds_dir}...')\n",
    "slf_ds = slf.reader.read_dataset(ds_dir)\n",
    "\n",
    "# Get the subject IDs\n",
    "subj_ids = list(slf_ds.series[series_name].subjects.keys())\n",
    "\n",
    "# Permutate subject IDs accordig to the same random seed as in training\n",
    "rng = np.random.default_rng(seed)\n",
    "permuted_subj_ids = rng.permutation(subj_ids)\n",
    "\n",
    "# Split the subject IDs to 'train', 'val', and 'test'\n",
    "logger.info('Creating the splits...')\n",
    "split_subj_ids = {}\n",
    "curr_split_start = 0\n",
    "for k, split in config['datasets'][ds_name]['splits'].items():\n",
    "    curr_split_end = curr_split_start + split['n']\n",
    "    split_subj_ids[k] = permuted_subj_ids[curr_split_start:curr_split_end]\n",
    "    curr_split_start = curr_split_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from scipy.io import savemat\n",
    "#savemat(Path('/home/hennpi/Documents',f\"{ds_name}_splits.mat\"),{f'{ds_name}_splits': split_subj_ids})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete unnecessary items from ds config before loading everything\n",
    "for ds in config['datasets']:\n",
    "    for item in config['datasets'][ds]['components'].copy():\n",
    "        if item not in config['model']['input_names'] and item not in config['model']['output_names']:\n",
    "            config['datasets'][ds]['components'].pop(item)\n",
    "\n",
    "# Load the slf Dataset\n",
    "logger.info('Loading the datasets...')\n",
    "ds = sds.compose.load_split_concat(config['datasets'], seed=seed)\n",
    "\n",
    "testset = ds['test']\n",
    "\n",
    "true_labels = []\n",
    "for subject in testset.as_numpy_iterator():\n",
    "   true_labels.append(subject[output_name])\n",
    "\n",
    "true_concat = np.concatenate(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = slf_ds.series[series_name]\n",
    "testsubject_ids = [subject_id for subject_id in series.subjects.keys() if subject_id in split_subj_ids['test']]\n",
    "\n",
    "output_index = [config['model']['output_args'][i]['output_name'] for i, _ in enumerate(config['model']['output_args'])].index(output_name)\n",
    "seg_length = config['model']['output_args'][output_index]['samples_per_segment']\n",
    "\n",
    "probabilities = []\n",
    "pred_labels = []\n",
    "for k, subj_id in enumerate(testsubject_ids):\n",
    "        subj = series.subjects[subj_id]\n",
    "        \n",
    "        # map model input names to correct signal source names:\n",
    "        input_source_names = {input_name: config['datasets'][ds_name]['components'][input_name]['src_name'] for input_name in config['model']['input_names']}\n",
    "\n",
    "        inputs = {input_name: subj.sample_arrays[input_source_names[input_name]].values_func()[np.newaxis, 0:np.shape(true_labels[k])[0]*seg_length] for input_name in config['model']['input_names']}\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "\n",
    "        probs = outputs[0]\n",
    "        probabilities.append(probs)\n",
    "        pred_labels.append(np.argmax(probs, axis=1))\n",
    "\n",
    "pred_concat = np.concatenate(pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AASM rules (arousals) or change to binary labels (hypnograms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_name == 'hypnogram' and savepath is None: # change 1-second segments of 5-stage output to 30-second segments of binary output (wake/sleep)\n",
    "    \n",
    "    e = 0\n",
    "    true_stages = []\n",
    "    pred_stages = []\n",
    "    while e+29 <= len(true_concat):\n",
    "        true_epoch = list(true_concat[e:e+29])\n",
    "        pred_epoch = list(pred_concat[e:e+29])\n",
    "\n",
    "        true_stage = max(set(true_epoch), key=true_epoch.count)\n",
    "        pred_stage = max(set(pred_epoch), key=pred_epoch.count)\n",
    "\n",
    "        true_stages.append(true_stage)\n",
    "        pred_stages.append(pred_stage)\n",
    "\n",
    "        e=e+30\n",
    "    \n",
    "    true_concat = list(map(lambda stage: 1 if stage > 0 else 0, true_stages))\n",
    "    pred_concat = list(map(lambda stage: 1 if stage > 0 else 0, pred_stages))\n",
    "    \n",
    "elif output_name == 'arousals': # remove less than 3 s arousals and arousals with less than 10 s sleep before it\n",
    "    arousal = []\n",
    "    previous_sleep_startpoint = -11\n",
    "    for i, seg in enumerate(pred_concat):\n",
    "        if seg == 1:\n",
    "            arousal.append(seg)\n",
    "        elif seg == 0 and len(arousal) > 0:\n",
    "            if len(arousal) < 3 or i-len(arousal)-1 - previous_sleep_startpoint < 10:\n",
    "                pred_concat[i-len(arousal):i-1] = 0\n",
    "            previous_sleep_startpoint = i\n",
    "            arousal = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as MAT-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if savepath is not None:\n",
    "    from scipy.io import savemat\n",
    "    true_vs_pred = np.stack([true_concat, pred_concat])\n",
    "    savemat(savepath,{f'{ds_name}_{output_name}': true_vs_pred})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_concat,pred_concat))\n",
    "\n",
    "kappa = cohen_kappa_score(true_concat,pred_concat)\n",
    "print('Cohen\\'s kappa: ' + str(kappa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(true, pred, class_names, title, figsize=(5,5), fontsize=22):\n",
    "     # Calculate comfusion matrix\n",
    "    cm = confusion_matrix(true, pred)\n",
    "    # Calculate the sum of true labels for each class and broadcast to cm shape\n",
    "    row_sums = np.tile(cm.sum(axis=1)[:, np.newaxis], (1, cm.shape[0]))\n",
    "    # Set normalized to 0.0 if there are zero true samples\n",
    "    norm_cm = np.divide(cm, row_sums, out=np.zeros_like(cm, dtype='float'), where=row_sums!=0)\n",
    "    norm_cm_df = pd.DataFrame(norm_cm, index=class_names, columns=class_names)\n",
    "\n",
    "    # Create annotations in the format of '<normalized>\\n(<count>)'\n",
    "    formatter = \"{0:.2f}\".format\n",
    "    annot = np.array([formatter(f) + '\\n(' + str(d) + ')' for f, d in\n",
    "                      zip(norm_cm.flatten(), cm.flatten())]).reshape(cm.shape)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.axes().set_aspect('equal')\n",
    "    sns.set_theme(font_scale=1.4)\n",
    "    sns.heatmap(norm_cm_df,\n",
    "                cmap=plt.cm.Purples,\n",
    "                vmin=0.0,\n",
    "                vmax=1.0,\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names,\n",
    "                annot=annot,\n",
    "                fmt='s',\n",
    "                cbar=False,\n",
    "                annot_kws={\"size\":fontsize-2})\n",
    "    plt.title(title, fontsize=fontsize+1)\n",
    "    plt.ylabel('Manual', fontsize=fontsize)\n",
    "    plt.xlabel('Automatic', fontsize=fontsize)\n",
    "    plt.show()\n",
    "\n",
    "plot_cm(true_concat, pred_concat, class_names=['Non-arousal','Arousal'], title = f'Cohen\\'s kappa = {kappa:.2f}', figsize=(5,5), fontsize=22)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "simultscoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
